{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Length of input Array= 3864\n",
      "12 12\n",
      "58 58\n",
      "30 30\n",
      "26 26\n",
      "40 40\n",
      "14 14\n",
      "4 4\n",
      "48 48\n",
      "38 38\n",
      "12 12\n",
      "36 36\n",
      "10 10\n",
      "18 18\n",
      "14 14\n",
      "30 30\n",
      "18 18\n",
      "38 38\n",
      "46 46\n",
      "4 4\n",
      "28 28\n",
      "4 4\n",
      "10 10\n",
      "30 30\n",
      "14 14\n",
      "34 34\n",
      "8 8\n",
      "54 54\n",
      "0 0\n",
      "done\n",
      "Tuning for Random Forest\n",
      "Tuning hyper-parameters for  precision\n",
      "Best parameters set found on development set:\n",
      "{'max_depth': 10, 'n_estimators': 400}\n",
      "Grid scores on development set:\n",
      "0.9949 (+/-0.0129) for {'max_depth': 5, 'n_estimators': 200}\n",
      "0.9918 (+/-0.0138) for {'max_depth': 5, 'n_estimators': 400}\n",
      "0.9939 (+/-0.0150) for {'max_depth': 5, 'n_estimators': 600}\n",
      "0.9939 (+/-0.0150) for {'max_depth': 5, 'n_estimators': 800}\n",
      "0.9949 (+/-0.0129) for {'max_depth': 5, 'n_estimators': 1000}\n",
      "0.9939 (+/-0.0119) for {'max_depth': 10, 'n_estimators': 200}\n",
      "0.9959 (+/-0.0100) for {'max_depth': 10, 'n_estimators': 400}\n",
      "0.9959 (+/-0.0100) for {'max_depth': 10, 'n_estimators': 600}\n",
      "0.9949 (+/-0.0092) for {'max_depth': 10, 'n_estimators': 800}\n",
      "0.9949 (+/-0.0092) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "Final Model Test Result is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       966\n",
      "           1       0.99      1.00      1.00       966\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1932\n",
      "   macro avg       1.00      1.00      1.00      1932\n",
      "weighted avg       1.00      1.00      1.00      1932\n",
      "\n",
      "Tuning hyper-parameters for  recall\n",
      "Best parameters set found on development set:\n",
      "{'max_depth': 10, 'n_estimators': 200}\n",
      "Grid scores on development set:\n",
      "0.9969 (+/-0.0083) for {'max_depth': 5, 'n_estimators': 200}\n",
      "0.9979 (+/-0.0051) for {'max_depth': 5, 'n_estimators': 400}\n",
      "0.9969 (+/-0.0083) for {'max_depth': 5, 'n_estimators': 600}\n",
      "0.9969 (+/-0.0083) for {'max_depth': 5, 'n_estimators': 800}\n",
      "0.9969 (+/-0.0083) for {'max_depth': 5, 'n_estimators': 1000}\n",
      "0.9990 (+/-0.0041) for {'max_depth': 10, 'n_estimators': 200}\n",
      "0.9990 (+/-0.0041) for {'max_depth': 10, 'n_estimators': 400}\n",
      "0.9990 (+/-0.0041) for {'max_depth': 10, 'n_estimators': 600}\n",
      "0.9990 (+/-0.0041) for {'max_depth': 10, 'n_estimators': 800}\n",
      "0.9979 (+/-0.0051) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "Final Model Test Result is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       966\n",
      "           1       0.99      1.00      1.00       966\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1932\n",
      "   macro avg       1.00      1.00      1.00      1932\n",
      "weighted avg       1.00      1.00      1.00      1932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import glob\n",
    "import os\n",
    "from configuration import *\n",
    "import numpy as np\n",
    "debug=1\n",
    "def balanced_split(p,y,split=0.3):\n",
    "    p1=[]\n",
    "    p2=[]\n",
    "    y1=[]\n",
    "    y2=[]\n",
    "    p11=[]\n",
    "    p22=[]\n",
    "    y11=[]\n",
    "    y22=[]\n",
    "    for i in range(len(y)):\n",
    "        if y[i]==1:\n",
    "            p1.append(p[i])\n",
    "            y1.append(y[i])\n",
    "        else:\n",
    "            p2.append(p[i])\n",
    "            y2.append(y[i])\n",
    "    pos_size=len(p1)\n",
    "    neg_size=len(p2)\n",
    "    if pos_size>neg_size:\n",
    "        for i in range(neg_size):\n",
    "            p11.append(p1[i])\n",
    "            p22.append(p2[i])\n",
    "            y11.append(y1[i])\n",
    "            y22.append(y2[i])\n",
    "    else:\n",
    "        for i in range(pos_size):\n",
    "            p22.append(p2[i])\n",
    "            p11.append(p1[i])\n",
    "            y11.append(y1[i])\n",
    "            y22.append(y2[i])\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    X=p11+p22\n",
    "    Y=y11+y22\n",
    "    if(debug==1):\n",
    "        print(\"Length of input Array=\",len(X))\n",
    "    t1=0\n",
    "    t2=0\n",
    "    flag_test=1\n",
    "    while flag_test==1:\n",
    "        x,y,x_,y_=train_test_split(X,Y,test_size=split)\n",
    "        one=0\n",
    "        zero=0\n",
    "        for i in range(len(x_)):\n",
    "            if x_[i]==1:\n",
    "                one+=1\n",
    "            else:\n",
    "                zero+=1\n",
    "        t1=abs(one-zero)\n",
    "        one=0\n",
    "        zero=0\n",
    "        for i in range(len(y_)):\n",
    "            if x_[i]==1:\n",
    "                one+=1\n",
    "            else:\n",
    "                zero+=1\n",
    "        t2=abs(one-zero)\n",
    "        if debug==1:\n",
    "            print(t1,t2)\n",
    "        if t1<=1:\n",
    "            if t2<=1:\n",
    "                flag_test=0\n",
    "                print(\"done\")\n",
    "    return x,y,x_,y_\n",
    "\n",
    "\n",
    "def soptimizer(x_train,y_train):\n",
    "     \n",
    "    parameters = [{'kernel': ['rbf'], 'gamma': [1e-2,1e-3,1e-4],'C': [1,10, 15]},\n",
    "                {'kernel': ['linear'], 'C': [1, 10,15]}]\n",
    "    scores = ['precision', 'recall']\n",
    "    print(\"Tuning for Support Vector Machine\")\n",
    "    for score in scores:\n",
    "        print(\"Tuning hyper-parameters for \" , score)\n",
    "        clf = GridSearchCV(SVC(), parameters, cv=5,scoring=score)\n",
    "        clf.fit(x_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        print(\"Grid scores on development set:\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.4f (+/-%0.04f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        print(\"Final Model Test Result is\")\n",
    "        \n",
    "def roptimizer(x_train,y_train):\n",
    "    parameters = [{\n",
    " 'max_depth': [5,10],\n",
    " 'n_estimators': [200, 400,600,800,1000]}] \n",
    "    print(\"Tuning for Random Forest\")\n",
    "    scores = ['precision', 'recall']\n",
    "    for score in scores:\n",
    "        print(\"Tuning hyper-parameters for \" , score)\n",
    "        clf = GridSearchCV(RandomForestClassifier(), parameters, cv=5,scoring=score)\n",
    "        clf.fit(x_train, y_train)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        print(\"Grid scores on development set:\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.4f (+/-%0.04f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "def gridsearch(svm=0,rdf=0):\n",
    "    k=0\n",
    "    fds = []\n",
    "    labels = []\n",
    "    # Load the positive features\n",
    "    for feat_path in glob.glob(os.path.join(train_pos_feat_ph,\"*.feat\")):\n",
    "        k+=1\n",
    "        print(\"+\",end=\"\")\n",
    "        fd = joblib.load(feat_path)\n",
    "        if(len(fd)==3780):\n",
    "            fds.append(fd)\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            print(\"Error in pos\",end=\"\")\n",
    "\n",
    "    # Load the negative features\n",
    "    for feat_path in glob.glob(os.path.join(train_neg_feat_ph,\"*.feat\")):\n",
    "        k+=1\n",
    "        print(\"-\",end=\"\")\n",
    "        fd = joblib.load(feat_path)\n",
    "        if(len(fd)==3780):\n",
    "            fds.append(fd)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            print(\"Error in neg\",end=\"\")\n",
    "    fds=np.array(fds)\n",
    "    labels=np.array(labels)\n",
    "    if(svm==1):\n",
    "        soptimizer(fds,labels)\n",
    "    else:\n",
    "        roptimizer(fds,labels)\n",
    "gridsearch(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
