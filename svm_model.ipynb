{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Length of input Array= 4072\n",
      "16 4\n",
      "20 34\n",
      "30 12\n",
      "26 30\n",
      "102 54\n",
      "40 6\n",
      "22 8\n",
      "8 20\n",
      "4 6\n",
      "16 20\n",
      "2 38\n",
      "6 24\n",
      "44 14\n",
      "18 24\n",
      "72 24\n",
      "46 50\n",
      "26 0\n",
      "18 24\n",
      "16 18\n",
      "6 48\n",
      "0 24\n",
      "8 44\n",
      "30 14\n",
      "6 10\n",
      "0 18\n",
      "22 6\n",
      "12 66\n",
      "2 26\n",
      "22 30\n",
      "4 8\n",
      "30 8\n",
      "8 30\n",
      "24 28\n",
      "10 10\n",
      "2 6\n",
      "32 14\n",
      "56 38\n",
      "8 42\n",
      "36 46\n",
      "40 50\n",
      "14 46\n",
      "0 14\n",
      "40 50\n",
      "16 30\n",
      "2 28\n",
      "28 8\n",
      "6 6\n",
      "30 12\n",
      "38 42\n",
      "6 18\n",
      "6 16\n",
      "28 34\n",
      "6 34\n",
      "22 12\n",
      "26 8\n",
      "6 10\n",
      "6 24\n",
      "46 10\n",
      "42 12\n",
      "30 8\n",
      "30 22\n",
      "30 2\n",
      "46 8\n",
      "76 4\n",
      "2 10\n",
      "4 14\n",
      "32 34\n",
      "2 10\n",
      "46 32\n",
      "6 8\n",
      "6 18\n",
      "2 2\n",
      "20 10\n",
      "22 4\n",
      "20 42\n",
      "0 18\n",
      "18 38\n",
      "20 10\n",
      "26 12\n",
      "44 20\n",
      "48 10\n",
      "26 6\n",
      "44 18\n",
      "22 24\n",
      "38 10\n",
      "26 0\n",
      "38 10\n",
      "60 40\n",
      "4 40\n",
      "20 8\n",
      "26 10\n",
      "10 76\n",
      "38 30\n",
      "8 6\n",
      "8 10\n",
      "8 38\n",
      "22 50\n",
      "68 16\n",
      "10 38\n",
      "22 22\n",
      "24 22\n",
      "36 22\n",
      "26 10\n",
      "34 6\n",
      "64 6\n",
      "6 6\n",
      "20 16\n",
      "14 12\n",
      "2 28\n",
      "16 42\n",
      "48 40\n",
      "46 6\n",
      "56 2\n",
      "26 22\n",
      "40 18\n",
      "12 18\n",
      "16 2\n",
      "14 34\n",
      "12 16\n",
      "30 22\n",
      "12 26\n",
      "48 4\n",
      "38 8\n",
      "26 18\n",
      "8 0\n",
      "44 2\n",
      "16 8\n",
      "6 46\n",
      "26 6\n",
      "48 0\n",
      "48 46\n",
      "58 32\n",
      "8 30\n",
      "2 30\n",
      "84 38\n",
      "78 72\n",
      "10 6\n",
      "32 40\n",
      "16 44\n",
      "14 4\n",
      "20 2\n",
      "62 26\n",
      "0 8\n",
      "18 8\n",
      "34 20\n",
      "62 44\n",
      "8 8\n",
      "30 26\n",
      "70 30\n",
      "12 52\n",
      "34 2\n",
      "18 28\n",
      "12 10\n",
      "30 14\n",
      "50 24\n",
      "28 4\n",
      "18 46\n",
      "32 20\n",
      "12 30\n",
      "30 30\n",
      "10 18\n",
      "8 2\n",
      "10 2\n",
      "4 2\n",
      "6 18\n",
      "36 30\n",
      "22 40\n",
      "10 28\n",
      "38 62\n",
      "44 62\n",
      "44 24\n",
      "50 4\n",
      "20 30\n",
      "22 52\n",
      "44 12\n",
      "16 10\n",
      "16 8\n",
      "4 42\n",
      "26 56\n",
      "20 10\n",
      "12 52\n",
      "10 18\n",
      "18 0\n",
      "4 2\n",
      "10 10\n",
      "2 2\n",
      "2 10\n",
      "32 24\n",
      "22 24\n",
      "18 60\n",
      "14 4\n",
      "4 8\n",
      "38 6\n",
      "24 18\n",
      "2 32\n",
      "20 10\n",
      "20 32\n",
      "6 4\n",
      "34 6\n",
      "10 14\n",
      "28 10\n",
      "28 38\n",
      "4 44\n",
      "18 4\n",
      "30 42\n",
      "42 4\n",
      "14 24\n",
      "16 20\n",
      "2 40\n",
      "4 28\n",
      "26 32\n",
      "32 4\n",
      "42 32\n",
      "8 8\n",
      "18 36\n",
      "46 4\n",
      "6 32\n",
      "66 20\n",
      "14 22\n",
      "8 8\n",
      "42 72\n",
      "2 4\n",
      "16 14\n",
      "14 54\n",
      "52 0\n",
      "2 16\n",
      "38 46\n",
      "8 26\n",
      "16 46\n",
      "56 24\n",
      "20 2\n",
      "10 42\n",
      "52 64\n",
      "24 10\n",
      "8 18\n",
      "6 18\n",
      "20 0\n",
      "20 10\n",
      "8 12\n",
      "32 12\n",
      "68 52\n",
      "28 22\n",
      "6 22\n",
      "4 12\n",
      "2 38\n",
      "28 14\n",
      "8 8\n",
      "40 0\n",
      "6 30\n",
      "42 32\n",
      "44 30\n",
      "28 30\n",
      "42 46\n",
      "6 18\n",
      "26 26\n",
      "6 4\n",
      "60 38\n",
      "12 6\n",
      "2 6\n",
      "44 38\n",
      "32 74\n",
      "6 48\n",
      "28 30\n",
      "34 52\n",
      "4 28\n",
      "22 6\n",
      "4 34\n",
      "50 30\n",
      "24 22\n",
      "0 0\n",
      "done\n",
      "Training a Linear SVM Classifier\n",
      "Test Accuracy of SVC =  1.0\n",
      "Classifier saved to data/models\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import glob\n",
    "import os\n",
    "from configuration import *\n",
    "import numpy as np\n",
    "debug=1\n",
    "def balanced_split(p,y,split=0.3):\n",
    "    p1=[]\n",
    "    p2=[]\n",
    "    y1=[]\n",
    "    y2=[]\n",
    "    p11=[]\n",
    "    p22=[]\n",
    "    y11=[]\n",
    "    y22=[]\n",
    "    for i in range(len(y)):\n",
    "        if y[i]==1:\n",
    "            p1.append(p[i])\n",
    "            y1.append(y[i])\n",
    "        else:\n",
    "            p2.append(p[i])\n",
    "            y2.append(y[i])\n",
    "    pos_size=len(p1)\n",
    "    neg_size=len(p2)\n",
    "    if pos_size>neg_size:\n",
    "        for i in range(neg_size):\n",
    "            p11.append(p1[i])\n",
    "            p22.append(p2[i])\n",
    "            y11.append(y1[i])\n",
    "            y22.append(y2[i])\n",
    "    else:\n",
    "        for i in range(pos_size):\n",
    "            p22.append(p2[i])\n",
    "            p11.append(p1[i])\n",
    "            y11.append(y1[i])\n",
    "            y22.append(y2[i])\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    X=p11+p22\n",
    "    Y=y11+y22\n",
    "    if(debug==1):\n",
    "        print(\"Length of input Array=\",len(X))\n",
    "    t1=0\n",
    "    t2=0\n",
    "    flag_test=1\n",
    "    while flag_test==1:\n",
    "        x,y,x_,y_=train_test_split(X,Y,test_size=split)\n",
    "        one=0\n",
    "        zero=0\n",
    "        for i in range(len(x_)):\n",
    "            if x_[i]==1:\n",
    "                one+=1\n",
    "            else:\n",
    "                zero+=1\n",
    "        t1=abs(one-zero)\n",
    "        one=0\n",
    "        zero=0\n",
    "        for i in range(len(y_)):\n",
    "            if x_[i]==1:\n",
    "                one+=1\n",
    "            else:\n",
    "                zero+=1\n",
    "        t2=abs(one-zero)\n",
    "        if debug==1:\n",
    "            print(t1,t2)\n",
    "        if t1<=1:\n",
    "            if t2<=1:\n",
    "                flag_test=0\n",
    "                print(\"done\")\n",
    "    return x,y,x_,y_\n",
    "\n",
    "def train_svm():\n",
    "    k=0\n",
    "    fds = []\n",
    "    labels = []\n",
    "    # Load the positive features\n",
    "    for feat_path in glob.glob(os.path.join(train_pos_feat_ph,\"*.feat\")):\n",
    "        k+=1\n",
    "        print(\"+\",end=\"\")\n",
    "        fd = joblib.load(feat_path)\n",
    "        if(len(fd)==3780):\n",
    "            fds.append(fd)\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            print(\"Error in pos\",end=\"\")\n",
    "\n",
    "    # Load the negative features\n",
    "    for feat_path in glob.glob(os.path.join(train_neg_feat_ph,\"*.feat\")):\n",
    "        k+=1\n",
    "        print(\"-\",end=\"\")\n",
    "        fd = joblib.load(feat_path)\n",
    "        if(len(fd)==3780):\n",
    "            fds.append(fd)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            print(\"Error in neg\",end=\"\")\n",
    "    fds=np.array(fds)\n",
    "    labels=np.array(labels)\n",
    "    fds_train,fds_test,labels_train,labels_test=balanced_split(fds,labels,split=0.3)\n",
    "    clf = svm.SVC(C=10,gamma=0.01,kernel='rbf')\n",
    "    print(\"Training a Linear SVM Classifier\")\n",
    "    clf.fit(fds_train,labels_train)\n",
    "    print('Test Accuracy of SVC = ', round(clf.score(fds_test, labels_test), 4))\n",
    "    if not os.path.isdir(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    fd_name=\"svm\"\n",
    "    fd_path = os.path.join(model_path, fd_name)\n",
    "    joblib.dump(clf, fd_path)\n",
    "    print(\"Classifier saved to\",model_path)\n",
    "train_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%r wew\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
